{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5eae700-a652-4354-9faf-50e426de7101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>3</td>\n",
       "      <td>£51.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>1</td>\n",
       "      <td>£53.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>1</td>\n",
       "      <td>£50.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>4</td>\n",
       "      <td>£47.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>5</td>\n",
       "      <td>£54.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>1</td>\n",
       "      <td>£22.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>4</td>\n",
       "      <td>£33.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>3</td>\n",
       "      <td>£17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>4</td>\n",
       "      <td>£22.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>1</td>\n",
       "      <td>£52.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>2</td>\n",
       "      <td>£13.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>4</td>\n",
       "      <td>£20.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>5</td>\n",
       "      <td>£17.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>5</td>\n",
       "      <td>£52.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>5</td>\n",
       "      <td>£35.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>3</td>\n",
       "      <td>£57.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>1</td>\n",
       "      <td>£23.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>1</td>\n",
       "      <td>£37.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>2</td>\n",
       "      <td>£51.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>2</td>\n",
       "      <td>£45.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Rating   Price\n",
       "0                                A Light in the Attic       3  £51.77\n",
       "1                                  Tipping the Velvet       1  £53.74\n",
       "2                                          Soumission       1  £50.10\n",
       "3                                       Sharp Objects       4  £47.82\n",
       "4               Sapiens: A Brief History of Humankind       5  £54.23\n",
       "5                                     The Requiem Red       1  £22.65\n",
       "6   The Dirty Little Secrets of Getting Your Dream...       4  £33.34\n",
       "7   The Coming Woman: A Novel Based on the Life of...       3  £17.93\n",
       "8   The Boys in the Boat: Nine Americans and Their...       4  £22.60\n",
       "9                                     The Black Maria       1  £52.15\n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)       2  £13.99\n",
       "11                              Shakespeare's Sonnets       4  £20.66\n",
       "12                                        Set Me Free       5  £17.46\n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...       5  £52.29\n",
       "14                          Rip it Up and Start Again       5  £35.02\n",
       "15  Our Band Could Be Your Life: Scenes from the A...       3  £57.25\n",
       "16                                               Olio       1  £23.88\n",
       "17  Mesaerion: The Best Science Fiction Stories 18...       1  £37.59\n",
       "18                       Libertarianism for Beginners       2  £51.33\n",
       "19                            It's Only the Himalayas       2  £45.17"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url='https://books.toscrape.com/'\n",
    "r=requests.get(url)\n",
    "soup=BeautifulSoup(r.content,'html.parser')\n",
    "data=[]\n",
    "nums = {\"One\":1, \"Two\":2, \"Three\":3, \"Four\":4, \"Five\":5}\n",
    "for d in soup.find_all('li',attrs={'class':\"col-xs-6 col-sm-4 col-md-3 col-lg-3\"}):\n",
    "    img = d.find('img')\n",
    "    title = img['alt']\n",
    "    stars = d.find('p',attrs={'class':'star-rating'})\n",
    "    stars = nums[stars['class'][1]]\n",
    "    price = d.find('p',attrs={'class':'price_color'}).text\n",
    "    availability = d.find('p',attrs={'class':'instock availability'}).text\n",
    "    obj = {\"Title\":title, \"Rating\":stars, \"Price\":price}\n",
    "    data.append(obj)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dca40f7-6d12-46f9-b014-836c0b3ae29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.36.0)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80aa785b-ff45-410e-8d25-b70eb221f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: selenium\n",
      "Version: 4.36.0\n",
      "Summary: Official Python bindings for Selenium WebDriver\n",
      "Home-page: https://www.selenium.dev\n",
      "Author: \n",
      "Author-email: \n",
      "License: Apache-2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages\n",
      "Requires: certifi, trio, trio-websocket, typing_extensions, urllib3, websocket-client\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d04ee4-b2fa-4833-b756-ec12bc77a38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/anaconda3/bin/python'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3e33be-f2da-4025-8520-e73ac6effe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting urllib3<3.0,>=2.5.0 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi>=2025.10.5 (from selenium)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting typing_extensions<5.0,>=4.15.0 (from selenium)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/anaconda3/lib/python3.13/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.31.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.31.0->selenium) (3.7)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/anaconda3/lib/python3.13/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/anaconda3/lib/python3.13/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.16.0 in /usr/local/anaconda3/lib/python3.13/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.3.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, urllib3, typing_extensions, outcome, certifi, trio, trio-websocket, selenium\n",
      "\u001b[2K  Attempting uninstall: urllib3\n",
      "\u001b[2K    Found existing installation: urllib3 2.3.0\n",
      "\u001b[2K    Uninstalling urllib3-2.3.0:\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.3.0\n",
      "\u001b[2K  Attempting uninstall: typing_extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.12.2\n",
      "\u001b[2K    Uninstalling typing_extensions-4.12.2:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.12.2━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [typing_extensions]\n",
      "\u001b[2K  Attempting uninstall: certifi0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Found existing installation: certifi 2025.4.26━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [typing_extensions]\n",
      "\u001b[2K    Uninstalling certifi-2025.4.26:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [typing_extensions]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.4.26━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/8\u001b[0m [typing_extensions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [selenium]7/8\u001b[0m [selenium]ions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.11.12 outcome-1.3.0.post0 selenium-4.38.0 trio-0.32.0 trio-websocket-0.12.2 typing_extensions-4.15.0 urllib3-2.5.0 wsproto-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbc8269d-4f9b-44dd-b56e-3dba9b5eaf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "def get_default_chrome_options():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    return options\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "driver = webdriver.Chrome() \n",
    "driver.get(\"https://quotes.toscrape.com/js/\") \n",
    "options = get_default_chrome_options()\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "quotes = driver.find_elements(By.CLASS_NAME, \"text\") \n",
    "data = []\n",
    "for q in quotes: \n",
    "    print(q.text)\n",
    "    data.append(q.text)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fea1e9c-8b35-4ed0-a5e7-a94807a6b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.36.0)\n",
      "Requirement already satisfied: webdriver-manager in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.31.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from webdriver-manager) (1.1.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->webdriver-manager) (3.4.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde5d678-e19d-4216-814a-883ab6ae23fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in /usr/local/anaconda3/lib/python3.13/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.13/site-packages (from requests->webdriver-manager) (2025.11.12)\n",
      "Using cached webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: webdriver-manager\n",
      "Successfully installed webdriver-manager-4.0.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install webdriver-manager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5595eed9-6386-43d6-bfbe-656a51807e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No next button found — reached last page.\n",
      "Saved 100 rows to quotes.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import (\n",
    "    NoSuchElementException, TimeoutException, StaleElementReferenceException\n",
    ")\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import csv\n",
    "\n",
    "URL = \"https://quotes.toscrape.com/js/\"\n",
    "\n",
    "def create_driver(headless=False):\n",
    "    opts = Options()\n",
    "    if headless:\n",
    "        opts.add_argument(\"--headless=new\")  # newer headless mode\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=opts)\n",
    "    return driver\n",
    "\n",
    "def scrape_all_pages():\n",
    "    driver = create_driver(headless=True)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    driver.get(URL)\n",
    "\n",
    "    results = []\n",
    "    page_index = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # Wait for quotes to be present on the current page\n",
    "            wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"quote\")))\n",
    "        except TimeoutException:\n",
    "            print(f\"Timed out waiting for quotes on page {page_index}. Stopping.\")\n",
    "            break\n",
    "\n",
    "        # Collect all quotes on the page\n",
    "        quotes = driver.find_elements(By.CLASS_NAME, \"quote\")\n",
    "        for q in quotes:\n",
    "            try:\n",
    "                text = q.find_element(By.CLASS_NAME, \"text\").text.strip()\n",
    "                author = q.find_element(By.CLASS_NAME, \"author\").text.strip()\n",
    "                tags = [t.text.strip() for t in q.find_elements(By.CLASS_NAME, \"tag\")]\n",
    "                results.append({\"quote\": text, \"author\": author, \"tags\": \";\".join(tags)})\n",
    "            except (StaleElementReferenceException, NoSuchElementException):\n",
    "                # element disappeared between find and access — skip it\n",
    "                continue\n",
    "\n",
    "        # Try to find and click the Next button. If not found, we're done.\n",
    "        try:\n",
    "            next_link = driver.find_element(By.CSS_SELECTOR, \"li.next a\")\n",
    "        except NoSuchElementException:\n",
    "            print(\"No next button found — reached last page.\")\n",
    "            break\n",
    "\n",
    "        # Click and wait for URL to change (safe navigation)\n",
    "        prev_url = driver.current_url\n",
    "        try:\n",
    "            next_link.click()\n",
    "        except Exception:\n",
    "            # fallback to JS click if normal click fails\n",
    "            driver.execute_script(\"arguments[0].click();\", next_link)\n",
    "\n",
    "        try:\n",
    "            wait.until(EC.url_changes(prev_url))\n",
    "        except TimeoutException:\n",
    "            # URL didn't change within timeout, but maybe content changed — attempt to continue\n",
    "            print(f\"Warning: URL didn't change after clicking Next on page {page_index}.\")\n",
    "        page_index += 1\n",
    "\n",
    "    driver.quit()\n",
    "    return results\n",
    "\n",
    "def save_to_csv(rows, filename=\"quotes.csv\"):\n",
    "    keys = [\"quote\", \"author\", \"tags\"]\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Saved {len(rows)} rows to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = scrape_all_pages()\n",
    "    save_to_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af093fe1-203a-4795-8b7b-7d2a93986c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "IMDB Top 250 Movies Scraper\n",
      "============================================================\n",
      "Initializing Chrome driver...\n",
      "Navigating to https://www.imdb.com/chart/top/...\n",
      "Page loaded successfully. Extracting movie data...\n",
      "Found 250 movies. Processing...\n",
      "Processed 50 movies...\n",
      "Processed 100 movies...\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def scrape_imdb_top250():\n",
    "    \"\"\"\n",
    "    Scrapes IMDB Top 250 Movies list and saves to CSV\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure Chrome options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')  # Run in background\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "    \n",
    "    # Initialize the driver\n",
    "    print(\"Initializing Chrome driver...\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to IMDB Top 250\n",
    "        url = \"https://www.imdb.com/chart/top/\"\n",
    "        print(f\"Navigating to {url}...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"ipc-metadata-list\")))\n",
    "        \n",
    "        print(\"Page loaded successfully. Extracting movie data...\")\n",
    "        \n",
    "        # Lists to store data\n",
    "        ranks = []\n",
    "        titles = []\n",
    "        years = []\n",
    "        ratings = []\n",
    "        \n",
    "        # Find all movie items\n",
    "        movie_items = driver.find_elements(By.CSS_SELECTOR, \"li.ipc-metadata-list-summary-item\")\n",
    "        \n",
    "        print(f\"Found {len(movie_items)} movies. Processing...\")\n",
    "        \n",
    "        for idx, item in enumerate(movie_items, 1):\n",
    "            try:\n",
    "                # Extract rank\n",
    "                rank = idx\n",
    "                \n",
    "                # Extract title\n",
    "                title_element = item.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\")\n",
    "                title_text = title_element.text\n",
    "                # Remove the rank prefix (e.g., \"1. The Shawshank Redemption\" -> \"The Shawshank Redemption\")\n",
    "                title = title_text.split('. ', 1)[1] if '. ' in title_text else title_text\n",
    "                \n",
    "                # Extract year\n",
    "                metadata = item.find_elements(By.CSS_SELECTOR, \"span.cli-title-metadata-item\")\n",
    "                year = metadata[0].text if metadata else \"N/A\"\n",
    "                \n",
    "                # Extract rating\n",
    "                rating_element = item.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star--imdb\")\n",
    "                rating_text = rating_element.get_attribute(\"aria-label\")\n",
    "                # Extract numeric rating from \"IMDb rating: 9.3\"\n",
    "                rating = rating_text.split(\": \")[1] if \": \" in rating_text else \"N/A\"\n",
    "                \n",
    "                # Append to lists\n",
    "                ranks.append(rank)\n",
    "                titles.append(title)\n",
    "                years.append(year)\n",
    "                ratings.append(rating)\n",
    "                \n",
    "                # Print progress every 50 movies\n",
    "                if idx % 50 == 0:\n",
    "                    print(f\"Processed {idx} movies...\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing movie {idx}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Successfully extracted data for {len(titles)} movies.\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'Rank': ranks,\n",
    "            'Movie Title': titles,\n",
    "            'Year of Release': years,\n",
    "            'IMDB Rating': ratings\n",
    "        })\n",
    "        \n",
    "        # Export to CSV\n",
    "        csv_filename = 'imdb_top250.csv'\n",
    "        df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "        print(f\"\\nData saved to '{csv_filename}'\")\n",
    "        \n",
    "        # Display first 10 rows\n",
    "        print(\"\\nFirst 10 movies:\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(f\"\\nTotal movies scraped: {len(df)}\")\n",
    "        print(f\"Average rating: {df['IMDB Rating'].astype(float).mean():.2f}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "        print(\"\\nBrowser closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"IMDB Top 250 Movies Scraper\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = scrape_imdb_top250()\n",
    "    \n",
    "    if df is not None:\n",
    "        print(\"\\n✓ Scraping completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Scraping failed. Please check the error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040aacb-33e7-4c72-9221-b54e473775e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "def scrape_weather_data():\n",
    "    \"\"\"\n",
    "    Scrapes weather information for top world cities from timeanddate.com\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure Chrome options\n",
    "    chrome_options = Options()\n",
    "    # chrome_options.add_argument('--headless')  # Uncomment for headless mode\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "    chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    \n",
    "    # Initialize the driver\n",
    "    print(\"Initializing Chrome driver...\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the weather page\n",
    "        url = \"https://www.timeanddate.com/weather/\"\n",
    "        print(f\"Navigating to {url}...\")\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for page to load completely\n",
    "        print(\"Waiting for page to load completely...\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Scroll down to load all content\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight/2);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        print(\"Page loaded. Extracting weather data...\")\n",
    "        \n",
    "        # Lists to store data\n",
    "        cities = []\n",
    "        temperatures = []\n",
    "        conditions = []\n",
    "        \n",
    "        # Find all table rows\n",
    "        all_rows = driver.find_elements(By.CSS_SELECTOR, \"table tr\")\n",
    "        \n",
    "        print(f\"Found {len(all_rows)} table rows. Processing...\")\n",
    "        \n",
    "        for row in all_rows:\n",
    "            try:\n",
    "                # Get all cells in this row\n",
    "                all_cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                \n",
    "                if len(all_cells) < 2:\n",
    "                    continue\n",
    "                \n",
    "                # Each row contains multiple cities\n",
    "                # Pattern: city link, time, weather+temp, wind | city link, time, weather+temp, wind | ...\n",
    "                # We need to process cells in groups\n",
    "                \n",
    "                i = 0\n",
    "                while i < len(all_cells):\n",
    "                    try:\n",
    "                        # Check if this cell contains a city link\n",
    "                        city_links = all_cells[i].find_elements(By.CSS_SELECTOR, \"a[href*='/weather/']\")\n",
    "                        \n",
    "                        if not city_links:\n",
    "                            i += 1\n",
    "                            continue\n",
    "                        \n",
    "                        city_name = city_links[0].text.strip()\n",
    "                        \n",
    "                        if not city_name or len(city_name) < 2:\n",
    "                            i += 1\n",
    "                            continue\n",
    "                        \n",
    "                        # Next cell should be time (class=\"r\"), skip it\n",
    "                        # The cell after that should contain weather image and temperature\n",
    "                        temperature = \"N/A\"\n",
    "                        condition = \"N/A\"\n",
    "                        \n",
    "                        # Look ahead for the weather data cell (usually 2 cells ahead)\n",
    "                        if i + 2 < len(all_cells):\n",
    "                            weather_cell = all_cells[i + 2]\n",
    "                            \n",
    "                            # Extract weather condition from image alt attribute\n",
    "                            try:\n",
    "                                weather_img = weather_cell.find_element(By.TAG_NAME, \"img\")\n",
    "                                condition = weather_img.get_attribute(\"alt\").strip()\n",
    "                                \n",
    "                                # Remove any extra text after period (e.g., \"Snow flurries. Overcast. Cold.\" -> \"Snow flurries\")\n",
    "                                if '.' in condition:\n",
    "                                    condition = condition.split('.')[0].strip()\n",
    "                            except:\n",
    "                                pass\n",
    "                        \n",
    "                        # Temperature is in the next cell (class=\"rbi\")\n",
    "                        if i + 3 < len(all_cells):\n",
    "                            temp_cell = all_cells[i + 3]\n",
    "                            cell_text = temp_cell.text.strip()\n",
    "                            \n",
    "                            # Extract temperature (format like \"-4 °C\" or \"25 °C\")\n",
    "                            # Remove &nbsp; and extract number with degree symbol\n",
    "                            cell_text = cell_text.replace('\\xa0', ' ')  # Replace &nbsp;\n",
    "                            temp_match = re.search(r'(-?\\d+)\\s*°[CF]?', cell_text)\n",
    "                            if temp_match:\n",
    "                                temperature = temp_match.group(1) + \"°C\"\n",
    "                        \n",
    "                        # Only add if we got at least temperature or condition\n",
    "                        if temperature != \"N/A\" or condition != \"N/A\":\n",
    "                            cities.append(city_name)\n",
    "                            temperatures.append(temperature)\n",
    "                            conditions.append(condition)\n",
    "                            \n",
    "                            if len(cities) % 25 == 0:\n",
    "                                print(f\"Processed {len(cities)} cities...\")\n",
    "                        \n",
    "                        # Move to next potential city (usually 4 cells ahead: city, time, weather, wind)\n",
    "                        i += 4\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                        \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nSuccessfully extracted data for {len(cities)} cities.\")\n",
    "        \n",
    "        if not cities:\n",
    "            print(\"\\n⚠ No weather data could be extracted.\")\n",
    "            print(\"The page structure may have changed or dynamic content didn't load.\")\n",
    "            return None\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'City Name': cities,\n",
    "            'Temperature': temperatures,\n",
    "            'Weather Condition': conditions\n",
    "        })\n",
    "        \n",
    "        # Remove duplicates (keep first occurrence)\n",
    "        df = df.drop_duplicates(subset=['City Name'], keep='first')\n",
    "        \n",
    "        # Export to CSV\n",
    "        csv_filename = 'weather.csv'\n",
    "        df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "        print(f\"\\nData saved to '{csv_filename}'\")\n",
    "        \n",
    "        # Display sample results\n",
    "        print(\"\\nSample Weather Data (first 20 cities):\")\n",
    "        print(df.head(20).to_string(index=False))\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Total cities scraped: {len(df)}\")\n",
    "        print(f\"Cities with temperature data: {len(df[df['Temperature'] != 'N/A'])}\")\n",
    "        print(f\"Cities with weather condition data: {len(df[df['Weather Condition'] != 'N/A'])}\")\n",
    "        \n",
    "        # Show some example weather conditions\n",
    "        unique_conditions = df[df['Weather Condition'] != 'N/A']['Weather Condition'].unique()\n",
    "        print(f\"\\nUnique weather conditions found: {len(unique_conditions)}\")\n",
    "        print(f\"Examples: {', '.join(list(unique_conditions)[:10])}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        print(\"\\nClosing browser...\")\n",
    "        driver.quit()\n",
    "        print(\"Browser closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Weather Information Scraper - TimeAndDate.com\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    df = scrape_weather_data()\n",
    "    \n",
    "    if df is not None and len(df) > 0:\n",
    "        print(\"\\n✓ Scraping completed successfully!\")\n",
    "    else:\n",
    "        print(\"\\n✗ Scraping failed. Please check the error messages above.\")\n",
    "        print(\"\\nTroubleshooting tips:\")\n",
    "        print(\"1. Make sure you have a stable internet connection\")\n",
    "        print(\"2. The website may have anti-scraping measures\")\n",
    "        print(\"3. Try running without headless mode to see what's happening\")\n",
    "        print(\"4. Check if the website structure has changed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
